# AWS TagSense Environment Configuration
# Copy this file to .env and fill in your actual values
# NEVER commit the .env file with real credentials!

# ============================================================================
# LLM Provider API Keys (at least one is required)
# ============================================================================

# OpenAI API Key (Primary)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-proj-your-openai-api-key-here

# Anthropic API Key (Optional - for Claude models)
# Get your key from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# ============================================================================
# LLM Configuration
# ============================================================================

# Primary LLM backend: openai | anthropic
# If primary fails, system will fallback to secondary
LLM_PRIMARY_BACKEND=openai

# Secondary LLM backend (fallback): openai | anthropic | none
LLM_FALLBACK_BACKEND=anthropic

# OpenAI Model (if using OpenAI backend)
# Options: gpt-4, gpt-4-turbo, gpt-3.5-turbo
OPENAI_MODEL=gpt-3.5-turbo

# Anthropic Model (if using Anthropic backend)
# Options: claude-3-5-sonnet-20241022, claude-3-opus-20240229, claude-3-sonnet-20240229
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# LLM Temperature (0.0 = deterministic, 1.0 = creative)
LLM_TEMPERATURE=0.3

# Max tokens for LLM responses
LLM_MAX_TOKENS=2048

# ============================================================================
# AWS Configuration
# ============================================================================

# Default AWS Region
AWS_DEFAULT_REGION=us-west-2

# Default AWS Profile (optional - uses default if not specified)
AWS_PROFILE=default

# Enable multi-region scanning (comma-separated list)
# Example: us-west-2,us-east-1,eu-west-1
AWS_REGIONS=us-west-2

# ============================================================================
# Application Configuration
# ============================================================================

# Enable debug logging
DEBUG=false

# Log level: DEBUG | INFO | WARNING | ERROR | CRITICAL
LOG_LEVEL=INFO

# Enable response caching (reduces API costs)
ENABLE_CACHE=true

# Cache TTL in seconds (default: 3600 = 1 hour)
CACHE_TTL=3600

# ============================================================================
# Optional: Advanced Settings
# ============================================================================

# Maximum retries for failed API calls
MAX_RETRIES=3

# Retry backoff multiplier (seconds)
RETRY_BACKOFF_MULTIPLIER=2

# Request timeout (seconds)
REQUEST_TIMEOUT=30
